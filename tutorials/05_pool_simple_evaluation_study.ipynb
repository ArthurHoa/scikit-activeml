{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The main purpose of this tutorial is to show how a simple comparison study can be realized using `scikit-activeml`. For this experiment, we use a repeated K-fold Cross-validation to evaluate the query strategies using two different classifiers. Our main focus is cleanly separating the repetitions, proper handling of random states and separation of test and training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from skactiveml.classifier import SklearnClassifier\n",
    "from skactiveml.pool import UncertaintySampling, RandomSampling, DiscriminativeAL\n",
    "from skactiveml.pool import CoreSet, TypiClust, Badge\n",
    "from skactiveml.utils import call_func, MISSING_LABEL\n",
    "\n",
    "import warnings\n",
    "mlp.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://localhost:8888\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Seed Management\n",
    "To guarantee that the experiment is reproducible, we have to set the random states for all components that might use one. To simplify this, we make all random seeds dependent of a single fixed random state and use helper functions to generate new seeds and random states. Keep in mind that the `master_random_state` should only be used to create new random states or random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_random_state = np.random.RandomState(0)\n",
    "\n",
    "def gen_seed(random_state:np.random.RandomState):\n",
    "    return random_state.randint(0, 2**31)\n",
    "\n",
    "def gen_random_state(random_state:np.random.RandomState):\n",
    "    return np.random.RandomState(gen_seed(random_state))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Set Generation\n",
    "We generate a data set of 100 data points with two clusters from the `make_blobs` method of `scikit-learn`. This method also returns the true labels of each data point. In practice, however, we do not know these labels unless we ask an oracle. The labels are stored in `y_true`, which acts as an oracle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "n_classes = 3\n",
    "n_centers_per_class = 10\n",
    "classes = np.arange(n_classes)\n",
    "X, centers = make_blobs(\n",
    "    n_features=n_features, centers=n_classes*n_centers_per_class, n_samples=400,\n",
    "    random_state=gen_seed(master_random_state))\n",
    "y_true = centers % n_classes\n",
    "bound = [[min(X[:, 0]), min(X[:, 1])], [max(X[:, 0]), max(X[:, 1])]]\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_true, cmap='jet')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Data set');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models and Query Strategies\n",
    "We handle the creation of classifiers and query strategies using factory functions to simplify the separation of classifiers and query strategies across repetitions and folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_factory_functions = {\n",
    "    'LogisticRegression': lambda classes, random_state: SklearnClassifier(\n",
    "        LogisticRegression(),\n",
    "        classes=classes,\n",
    "        random_state=gen_seed(random_state)\n",
    "    )\n",
    "}\n",
    "\n",
    "query_strategy_factory_functions = {\n",
    "    'RandomSampling': lambda random_state: RandomSampling(random_state=gen_seed(random_state)),\n",
    "    'UncertaintySampling': lambda random_state: UncertaintySampling(random_state=gen_seed(random_state)),\n",
    "    'DiscriminativeAL': lambda random_state: DiscriminativeAL(random_state=gen_seed(random_state)),\n",
    "    'CoreSet': lambda random_state: CoreSet(random_state=gen_seed(random_state)),\n",
    "    'TypiClust': lambda random_state: TypiClust(random_state=gen_seed(random_state)),\n",
    "    'Badge': lambda random_state: Badge(random_state=gen_seed(random_state))\n",
    "}\n",
    "\n",
    "query_strategy_params_undefault = {\n",
    "    'RandomSampling': {} ,\n",
    "    'UncertaintySampling': {},\n",
    "    'DiscriminativeAL': {}, \n",
    "    'CoreSet': {},\n",
    "    'TypiClust': {},\n",
    "    'Badge': {}\n",
    "}\n",
    "\n",
    "def create_classifier(name, classes, random_state):\n",
    "    return classifier_factory_functions[name](classes, random_state)\n",
    "\n",
    "def create_query_strategy(name, random_state):\n",
    "    return query_strategy_factory_functions[name](random_state)\n",
    "\n",
    "def set_query_param_undefault(name, param):\n",
    "    query_param = query_strategy_params_undefault[name]\n",
    "    if name == 'UncertaintySampling':\n",
    "        query_param['clf'] = param\n",
    "    elif name == 'DiscriminativeAL':\n",
    "        query_param['discriminator'] = param\n",
    "    elif name == 'Badge':\n",
    "        query_param['clf'] = param\n",
    "    return query_param"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, we need to define how the strategies should be compared against one another. As we want to use a repeated K-Fold Cross-validation, we need to define the number of repetitions (`n_reps`), the number of folds (`n_folds`) and the number of queries within each fold. Furthermore, we have the option of using stratified Cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reps = 10\n",
    "n_folds = 5\n",
    "n_cycles = 50\n",
    "use_stratified = True\n",
    "classifier_names = classifier_factory_functions.keys()\n",
    "query_strategy_names = query_strategy_factory_functions.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Loop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual experiment loops over all query strategy and classifier combinations. The average accuracy over the test set is recorded for each cycle and stored in the `results` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "kfold_class = StratifiedKFold if use_stratified else KFold\n",
    "\n",
    "for clf_name in classifier_names:\n",
    "    for qs_name in query_strategy_names:\n",
    "        accuracies = np.full((n_reps, n_folds, n_cycles), np.nan)\n",
    "        for i_rep in range(n_reps):\n",
    "            kf = kfold_class(n_splits=n_folds, shuffle=True, random_state=gen_seed(master_random_state))\n",
    "            for i_fold, (train_idx, test_idx) in enumerate(kf.split(X, y_true)):\n",
    "                X_test = X[test_idx]\n",
    "                y_test = y_true[test_idx]\n",
    "\n",
    "                X_train = X[train_idx]\n",
    "                y_train_true = y_true[train_idx]\n",
    "                y_train = np.full(shape=y_train_true.shape, fill_value=MISSING_LABEL)\n",
    "\n",
    "                clf = create_classifier(clf_name, classes, gen_random_state(master_random_state))\n",
    "                qs = create_query_strategy(qs_name, gen_random_state(master_random_state))\n",
    "                clf.fit(X_train, y_train)\n",
    "\n",
    "                query_param = query_strategy_params_undefault[qs_name]\n",
    "                query_param = set_query_param_undefault(qs_name, clf)\n",
    "                \n",
    "                for c in range(n_cycles):\n",
    "                    query_idx = call_func(qs.query, X=X_train, y=y_train, batch_size=1, **query_param)\n",
    "                    y_train[query_idx] = y_train_true[query_idx]\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    accuracies[i_rep, i_fold, c] = clf.score(X_test, y_test)\n",
    "        results[(clf_name, qs_name)] = accuracies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Plotting\n",
    "We use learning curves to compare the strategies. For that, we plot the average accuracy (averaged over all repetitions and folds) relative to the number of queries. The error bars show the standard deviation for each curve. Furthermore, the legend shows the area under the learning curve, i.e., mean accuracy over all cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_name in classifier_names:\n",
    "    for qs_name in query_strategy_names:\n",
    "        key = (clf_name, qs_name)\n",
    "        result = results[key]\n",
    "        reshaped_result = result.reshape((-1, n_cycles))\n",
    "        errorbar_mean = np.mean(reshaped_result, axis=0)\n",
    "        errorbar_std = np.std(reshaped_result, axis=0)\n",
    "        plt.errorbar(np.arange(n_cycles), errorbar_mean, errorbar_std, label=f\"({np.mean(errorbar_mean):.4f}) {qs_name}\", alpha=0.5)\n",
    "    plt.title(clf_name)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('cycle')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the result\n",
    "Load the result with mlflow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"Evaluation\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    for clf_name in classifier_names:\n",
    "        for qs_name in query_strategy_names:\n",
    "            key = (clf_name, qs_name)\n",
    "            result = results[key]\n",
    "            reshaped_result = result.reshape((-1, n_cycles))\n",
    "            errorbar_mean = np.mean(reshaped_result, axis=0)\n",
    "            errorbar_std = np.std(reshaped_result, axis=0)\n",
    "            \n",
    "            mlflow.log_metric(f\"errorbar_mean for {qs_name} with {clf_name}\", errorbar_mean[-1])\n",
    "            mlflow.log_metric(f\"errorbar_std for {qs_name} with {clf_name}\", errorbar_std[-1])\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"Basic LR model for make blobs\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('scikit-activeml_new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f7f39fe3328ce4c80050dfed4bc981a4accefc504063131eb9a2382ee31ded5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
